---
layout: page
title: Minimal Understanding of MCMC
nav: false
---
<link rel="stylesheet" href="/assets/css/main.css"/>

## Introduction

Many times we can estimate a statistic from a given distribution \\(X\\),
drawing random i.i.d samples from it. For example, the mean

\\[
\frac{1}{n}\sum_i f(X_i) \sim \textbf{E}(f(X))
tag{1.1}
\\]

The law of the large numbers, ensure we'll get a decent estimation if enough
samples are drawn. This method works well until we can no longer sample from
the distribution. This can sound a bit harsh, but it's a pretty common
situation in bayesian inference when we try to compute the posterior
distribution. Even in simple situations the posterior can't be calculated.
Consider the model

```python
import pyro
import pyro.distributions as dist

def model(): 
    mu = pyro.sample("mu", dist.HalfCauchy(scale=1)) 
    return pyro.sample("obs", dist.Normal(mu, 1)) 
```
<br>

Imagine we condition this model on some data. We can always compute the bayes
numerator, our problem is the evidence


\\[
\textbf{P}(X) = \int_0^{\infty}
\frac{1}{1+\mu^2}\exp\left(-\frac{1}{2}\sum_{i=1}^{n} (\mu - x_i)^2\right)
\tag{1.2}
\\]

Which is an intractable integral. This is just to estimate one parameter, so we
can imagine what could happen when there is a bunch of them.

Given this problem, we're going to review the Markov Chain Monte Carlo
algorithm, that allow us to approximate those distributions and sample from
them. Even though MCMC is pretty old, still remains as the way to go resolve
this problem and popular packages, such as facebook prophet, were develop using
it.

## What is MCMC?

There is several versions of MCMC, but in general the idea is to generate a
Markov Chain whose stationary distribution is the one we want to sample
from. 

The chain is generated by proposing candidates from another distribution
\\(q\\) (the proposal) and then accept it or reject it according to a
probability \\(\alpha\\).

1. If we are at \\(X_n = x\\), sample \\(y\\) from \\(q(x, y)\))
2. Compute \\(\alpha(x,y)\\) 
3. Accept the proposal with probability \\(\alpha(x,y)\\). If accepted, set
\\(X_{n+1} = y\\) else \\(X_n=x\\)

One of the earlier MCMC method it's called Hasting-Metropolis. For this 
particular algorithm, the \\(\alpha\\) is given by

\\[
\alpha(x,y) = \min\left(1,\frac{q(y,x)*\pi(y)}{q(x,y)*\pi(x)}\right)
\\]

We'll review more details about why and how MCMC works, but first let's take a
look at the next example

## Toy example

Suppose we want to apply the Metropolis-Hasting algorithm to sample from a
distribution with finite domain. This isn't the most likely case someone would
use the algorithm but it's much easier to illustrate it on this way.

Let's compute the entries of the transition matrix.  If \\(i \neq j\\) the
probability of jumping from \\(i\\) to \\(j\\) can be interpreted as picking
\\(j\\) and the accept it. As those process are independent we have

\\[
p_{ij}=\textbf{P}[X_{n+1}=i|X_n=j]=q(i,j)\alpha(i,j)
\tag{1.3}
\\]

The rows have to sum 1, so the simplest way to compute \\(p_{ii}\\) is through
complement 

\\[
p_{ii} = 1 - \sum_{i\neq j} p_{ij}
\tag{1.4}
\\]

The whole matrix can be constructed with this code

```python
def compute_transition_matrix(pi, q, size):
    alpha = lambda x, y: \
        min(1, (pi(y) * q(y,x)) / (pi(x) * q(x,y))) if x != y else 0
    fn = lambda x, y: q(x, y) * alpha(x, y)  
    g = np.indices((size, size))
    P = np.vectorize(fn, otypes=[np.float64])(g[0], g[1])
    np.fill_diagonal(P, 1 - P.sum(axis=1))
    return P
```
<br>

Suppose now we're trying to sample from \\(bin(n, p)\\) (state space
\\(S=\{0,\ldots, n\}\\).

```python
class binom_mcmc:
    def __init__(self, n, p):
        self.n = n
	self.dist = binom(n, p)
		  
    def _pi(self, *args):
	return self.dist.pmf(*args)
				       
    @property
    def pi(self):
	return self._pi(range(self.n + 1))
	     
    def transition_matrix(self, q=None):
	if not q: q = self.unif_q
        return compute_transition_matrix(self._pi, q, self.n + 1)
		     
    def unif_q(self, *args):
	return 1 / (self.n + 1)
```
<br>

Take a look at the matrix when \\(n=3\\) and \\(p=.4\\).

```python
bm = binom_mcmc(3, .4)

P = bm.transition_matrix()
```
This \\(P\\) looks like 

\\[
P = \begin{bmatrix}
0.4259 & 0.25   & 0.25   & 0.0740 \\
0.125  & 0.6712 & 0.1667 & 0.0370 \\
0.1875 & 0.25   & 0.5069 & 0.0556 \\
0.25   & 0.25   & 0.25   & 0.25
\end{bmatrix}
\\]

Let's verify if \\(\pi\\) is a stationary distribution 

```python
assert np.allclose(v @ P, v)
```
<br>
We can check with a different proposal

```python
def binom_q(value, *args):
    return binom(3, .7).pmf(value)

Q = bm.transition_matrix(binom_q)
assert np.allclose(v @ Q, v)
```
<br>

## Why the chain converge?
